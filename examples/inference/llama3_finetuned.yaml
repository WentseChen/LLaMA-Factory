model_name_or_path: /dev/shm/fine_tuned_models/fft/checkpoint
template: llama3
infer_backend: vllm
vllm_enforce_eager: true
vllm_maxlen: 8192

